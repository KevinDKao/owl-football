{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook will pull data for each player for each game as much as possible as well as the outcome of each game, then output the file to a feather file so it's prepared for more ML work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Pull Player Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats\n",
    "\n",
    "players = stats.get_player_season_stats(year=2023, season_type=\"regular\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Pull Draft Pick States for that Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import draft\n",
    "\n",
    "draft = draft.get_draft_picks(year=2024)\n",
    "draft.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Merge it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def merge_player_draft_data(players, draft):\n",
    "    \"\"\"\n",
    "    Merge player statistics with draft data, ensuring all stat categories\n",
    "    exist for each player with zeros for missing values.\n",
    "\n",
    "    Parameters:\n",
    "    players (DataFrame): Player statistics with columns including playerId, category, statType, stat\n",
    "    draft (DataFrame): Draft data with collegeAthleteId\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Draft data with player statistics added as columns\n",
    "    \"\"\"\n",
    "    # Step 1: Get all unique stat combinations\n",
    "    stat_combinations = players[[\"category\", \"statType\"]].drop_duplicates()\n",
    "    print(f\"Found {len(stat_combinations)} unique category-statType combinations\")\n",
    "\n",
    "    # Ensure consistent types for both IDs before comparison\n",
    "    # Convert playerId to numeric type if it's not already\n",
    "    if players[\"playerId\"].dtype != \"int64\":\n",
    "        players[\"playerId\"] = pd.to_numeric(players[\"playerId\"], errors=\"coerce\")\n",
    "        # Drop rows with NaN playerId\n",
    "        players = players.dropna(subset=[\"playerId\"])\n",
    "        # Convert to int64\n",
    "        players[\"playerId\"] = players[\"playerId\"].astype(\"int64\")\n",
    "\n",
    "    # For draft data, handle NaN values differently - we'll keep them\n",
    "    # Convert collegeAthleteId to numeric type if it's not already\n",
    "    if draft[\"collegeAthleteId\"].dtype != \"int64\":\n",
    "        draft[\"collegeAthleteId\"] = pd.to_numeric(\n",
    "            draft[\"collegeAthleteId\"], errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    # Create a mask for non-NaN values\n",
    "    valid_ids_mask = ~draft[\"collegeAthleteId\"].isna()\n",
    "\n",
    "    # Only convert non-NaN values to int64\n",
    "    if valid_ids_mask.any():\n",
    "        draft.loc[valid_ids_mask, \"collegeAthleteId\"] = draft.loc[\n",
    "            valid_ids_mask, \"collegeAthleteId\"\n",
    "        ].astype(\"int64\")\n",
    "\n",
    "    # Step 2: Prepare columns for result DataFrame\n",
    "    # Generate all stat column names\n",
    "    stat_columns = [f\"{cat}_{stat}\" for _, (cat, stat) in stat_combinations.iterrows()]\n",
    "\n",
    "    # Step 3: Initialize result DataFrame with all stats set to 0\n",
    "    result = draft.copy()\n",
    "    for col in stat_columns:\n",
    "        result[col] = 0.0  # Initialize as float\n",
    "\n",
    "    # Step 4: Create a more efficient way to look up stats - use groupby and pivot\n",
    "    # This creates a DataFrame with playerId as index and all stat combinations as columns\n",
    "    stat_df = pd.DataFrame()\n",
    "\n",
    "    # Group by playerId and apply wide_to_long transformation for each category-statType\n",
    "    for _, row in stat_combinations.iterrows():\n",
    "        category = row[\"category\"]\n",
    "        stat_type = row[\"statType\"]\n",
    "        column_name = f\"{category}_{stat_type}\"\n",
    "\n",
    "        # Create a temporary DataFrame with the specific stat\n",
    "        temp_df = players[\n",
    "            (players[\"category\"] == category) & (players[\"statType\"] == stat_type)\n",
    "        ][[\"playerId\", \"stat\"]].copy()\n",
    "\n",
    "        # Rename 'stat' column to the specific stat name\n",
    "        temp_df.rename(columns={\"stat\": column_name}, inplace=True)\n",
    "\n",
    "        # First time, create the stat_df; otherwise merge\n",
    "        if stat_df.empty:\n",
    "            stat_df = temp_df\n",
    "        else:\n",
    "            stat_df = pd.merge(stat_df, temp_df, on=\"playerId\", how=\"outer\")\n",
    "\n",
    "    # Fill any NaN values with 0\n",
    "    stat_df = stat_df.fillna(0)\n",
    "\n",
    "    # Step 5: For better performance, merge the stats with the draft data at once\n",
    "    # Create a dict for easy lookup by playerId\n",
    "    stat_dict = stat_df.set_index(\"playerId\").to_dict(\"index\")\n",
    "\n",
    "    # Step 6: Populate stats for each draft pick\n",
    "    for idx, row in result.iterrows():\n",
    "        college_id = row[\"collegeAthleteId\"]\n",
    "\n",
    "        # Skip if NaN\n",
    "        if pd.isna(college_id):\n",
    "            continue\n",
    "\n",
    "        # Make sure college_id is an integer before lookup\n",
    "        try:\n",
    "            college_id_int = int(college_id)\n",
    "            # Get stats for this player\n",
    "            player_stats = stat_dict.get(college_id_int, {})\n",
    "\n",
    "            # Update stats in result DataFrame\n",
    "            for stat_column, value in player_stats.items():\n",
    "                result.loc[idx, stat_column] = float(value)\n",
    "\n",
    "        except (ValueError, TypeError):\n",
    "            # If conversion fails, skip this row\n",
    "            continue\n",
    "\n",
    "    # Ensure all NaN values are converted to 0\n",
    "    result.fillna(0, inplace=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "result_df = merge_player_draft_data(players, draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Add Remaining Players (Undrafted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_remaining_players(result_df, players_df):\n",
    "    \"\"\"\n",
    "    Add players from players_df that are not already in result_df\n",
    "    by putting their playerId into collegeAthleteId and setting overall to 0\n",
    "\n",
    "    Parameters:\n",
    "    result_df (DataFrame): Draft data with player statistics\n",
    "    players_df (DataFrame): Original player statistics\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Combined data with all players\n",
    "    \"\"\"\n",
    "    # Get unique player IDs from both dataframes\n",
    "    result_player_ids = set(result_df[\"collegeAthleteId\"].dropna().astype(int))\n",
    "    all_player_ids = set(players_df[\"playerId\"].unique())\n",
    "\n",
    "    # Find player IDs that are in players_df but not in result_df\n",
    "    missing_player_ids = all_player_ids - result_player_ids\n",
    "    print(f\"Found {len(missing_player_ids)} players to add\")\n",
    "\n",
    "    if not missing_player_ids:\n",
    "        return result_df  # No players to add\n",
    "\n",
    "    # Get the column structure from result_df\n",
    "    result_columns = result_df.columns.tolist()\n",
    "\n",
    "    # Get all stat columns\n",
    "    stat_columns = [\n",
    "        col\n",
    "        for col in result_columns\n",
    "        if \"_\" in col and col not in [\"collegeId\", \"nflTeamId\"]\n",
    "    ]\n",
    "\n",
    "    # Create a dictionary to hold stats for each missing player\n",
    "    player_rows = []\n",
    "\n",
    "    # Group players_df by playerId to get all stats for each player\n",
    "    grouped_players = players_df.groupby(\"playerId\")\n",
    "\n",
    "    # For each missing player, create a new row\n",
    "    for player_id in missing_player_ids:\n",
    "        # Start with a row filled with NaN/0\n",
    "        new_row = {col: 0 for col in result_columns}\n",
    "\n",
    "        # Set collegeAthleteId to the player's ID\n",
    "        new_row[\"collegeAthleteId\"] = player_id\n",
    "\n",
    "        # If this player exists in the grouped data\n",
    "        if player_id in grouped_players.groups:\n",
    "            player_data = grouped_players.get_group(player_id)\n",
    "\n",
    "            # Add player info if available\n",
    "            if \"player\" in player_data.columns:\n",
    "                new_row[\"name\"] = player_data[\"player\"].iloc[0]\n",
    "\n",
    "            if \"team\" in player_data.columns:\n",
    "                new_row[\"collegeTeam\"] = player_data[\"team\"].iloc[0]\n",
    "\n",
    "            if \"conference\" in player_data.columns:\n",
    "                new_row[\"collegeConference\"] = player_data[\"conference\"].iloc[0]\n",
    "\n",
    "            # Add stats for this player\n",
    "            for _, row in player_data.iterrows():\n",
    "                category = row.get(\"category\", \"\")\n",
    "                stat_type = row.get(\"statType\", \"\")\n",
    "                if category and stat_type:\n",
    "                    col_name = f\"{category}_{stat_type}\"\n",
    "                    if col_name in stat_columns:\n",
    "                        new_row[col_name] = row.get(\"stat\", 0)\n",
    "\n",
    "        player_rows.append(new_row)\n",
    "\n",
    "    # Create DataFrame from the new rows\n",
    "    new_players_df = pd.DataFrame(player_rows)\n",
    "\n",
    "    # Set column types to match result_df\n",
    "    for col in result_columns:\n",
    "        if col in new_players_df.columns and col in result_df.columns:\n",
    "            new_players_df[col] = new_players_df[col].astype(result_df[col].dtype)\n",
    "\n",
    "    # Combine with original result_df\n",
    "    combined_df = pd.concat([result_df, new_players_df], ignore_index=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# Usage:\n",
    "final_df = add_remaining_players(result_df, players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Export to Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_feather_export(df):\n",
    "    \"\"\"\n",
    "    Prepare a DataFrame for feather export by fixing type issues\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Handle object columns - convert to string\n",
    "    object_columns = df_clean.select_dtypes(include=[\"object\"]).columns\n",
    "    for col in object_columns:\n",
    "        # Convert non-string objects to strings\n",
    "        df_clean[col] = df_clean[col].astype(str)\n",
    "\n",
    "    # Handle int64/float64 conversion for numeric columns\n",
    "    numeric_columns = df_clean.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    for col in numeric_columns:\n",
    "        # Ensure numeric columns are float64 for consistency\n",
    "        df_clean[col] = df_clean[col].astype(\"float64\")\n",
    "\n",
    "    # Fix any potential datetime columns\n",
    "    datetime_columns = df_clean.select_dtypes(include=[\"datetime64\"]).columns\n",
    "    for col in datetime_columns:\n",
    "        # Convert to string if needed\n",
    "        df_clean[col] = df_clean[col].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# Usage:\n",
    "cleaned_df = prepare_for_feather_export(final_df)\n",
    "cleaned_df.to_feather(\"draft_data.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
